# ğŸ¤– Next LLM Chatbot (Next.js + Ollama)

A modern, ChatGPT-style AI chat application built with **Next.js (App Router)** and powered by a **local Large Language Model (LLM)** using **Ollama**.  
This project demonstrates clean frontend architecture, **real-time streaming AI responses**, prompt engineering, and real-world GenAI application patterns.

---

## âœ¨ Features

- ğŸ§  AI-powered chat using a **local LLM (Ollama + LLaMA 3 / Phi-3)**
- ğŸ’¬ Chat-style UI with user & assistant message bubbles
- âš¡ **Real-time streaming responses (token-by-token)**
- â³ Typing / thinking indicator during AI generation
- ğŸ’¾ Persistent chat history using **browser localStorage**
- ğŸ§© Clean separation of concerns (UI, hooks, storage, API)
- ğŸ¯ Structured **system prompt management**
- ğŸ”Œ LLM-agnostic backend design (easy to switch models/providers)

---

## ğŸ›  Tech Stack

- **Frontend:** React, Next.js (App Router)
- **Backend:** Next.js API Routes
- **LLM Runtime:** Ollama (local)
- **Models:** LLaMA 3 / Phi-3 (configurable)
- **State Management:** React Hooks
- **Persistence:** Browser `localStorage`
- **Streaming:** Fetch API + ReadableStream (NDJSON)
- **Styling:** CSS / Tailwind CSS

---

## ğŸ“‚ Project Structure

```
src/
â”‚
â”œâ”€ app/
â”‚   â”œâ”€ page.js                # Landing page
â”‚   â”œâ”€ chat/
â”‚   â”‚   â””â”€ page.js            # Chat UI page
â”‚   â”‚
â”‚   â””â”€ api/
â”‚       â””â”€ chat/
â”‚           â””â”€ route.js       # Streaming API â†’ Ollama integration
â”‚
â”œâ”€ hooks/
â”‚   â””â”€ useChat.js             # Chat logic & streaming state management
â”‚
â”œâ”€ lib/
â”‚   â”œâ”€ storage.js             # localStorage abstraction
â”‚   â”œâ”€ prompts.js             # System prompt definitions
    â””â”€ utils.js               # Utility functions
â”‚
â”œâ”€ components/
â”‚   â”œâ”€ ChatBubble.jsx
|   â”œâ”€ ChatHeader.jsx
|   â”œâ”€ ChatMessage.jsx
|   â””â”€ ChatFooter.jsx
â”‚
â””â”€ README.md
```

---

## âš™ï¸ How It Works

1. User sends a message from the chat UI  
2. Message is saved to React state and `localStorage`  
3. Recent conversation context (last N messages) is sent to `/api/chat`  
4. Backend API builds a prompt using a **system prompt + chat history**  
5. Ollama generates a response using **streaming mode**  
6. The API forwards the **NDJSON stream** directly to the client  
7. Frontend parses the stream and renders the response **token by token**  
8. Final response is saved and persisted  

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Prerequisites

- **Node.js** (v18+ recommended)  
- **Ollama** installed â†’ https://ollama.com  

Pull and run a model:

```bash
ollama run llama3
```

If you face CUDA/GPU issues on Windows, run Ollama in CPU mode:

```bash
set OLLAMA_NO_CUDA=1
ollama run llama3
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

---

### 3ï¸âƒ£ Start the Development Server

```bash
npm run dev
```

Open:

- http://localhost:3000  
- http://localhost:3000/chat  

---

## ğŸ¦™ Ollama Configuration

- Ollama runs at: `http://localhost:11434`  
- Endpoint used: `POST /api/generate`  

Model selection in `app/api/chat/route.js`:

```js
model: "llama3"
```

or

```js
model: "phi3"
```

---

## ğŸ’¾ Data Persistence

- Chat messages are stored in **browser localStorage**
- Messages persist across page refreshes
- Storage layer is abstracted for future DB integration

---

## ğŸ§  Design Decisions

- localStorage for rapid iteration
- Streaming responses for better UX
- NDJSON parsing for token-level updates
- System prompt abstraction for prompt control
- Context window limiting to avoid token bloat
- UUID-based message IDs
- Fetch API chosen for streaming compatibility

---

## ğŸ”® Future Improvements

- â›” Stop / cancel generation (AbortController)
- ğŸ—‚ Chat history summarization
- ğŸ› Multiple prompt modes
- ğŸ§  RAG (document-based Q&A)
- ğŸ” Authentication
- â˜ï¸ Hosted LLM support
- ğŸš€ Production deployment

---

## ğŸ“¸ Screenshots

![Chat UI](image-2.png)  
![Streaming Response](image-1.png)  
![Landing Page](image.png)

---

## ğŸ‘¨â€ğŸ’» Author

**Shubham Kiran Raut**  
Frontend Developer | React | GenAI

---

â­ If you like this project, consider giving it a star!
